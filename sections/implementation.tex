% TODO: Add details about SSL session key management and book keeping in the
% enclave
%NGINX achieves state of the art performance in commodity hardware due to its
%event-driven design which renders the web server capable of scaling to
%hundends of thousands of concurrent connections. This architecture introduced
%an implication in our design regarding handling concurrent SSL handshakes.
%Although an implementation detail, we explain further a simple scheme we used
%for supporting NGINX's behaviour, as it was a crucial part of our final
%performance evaluation results\footnote{Not dealing with concurrent
%connections, would mean that the enclave would be only be able to handle a
%single connection at a time which would end up in severe performance penalties
%in our results.}. According to an event-driven architecture, instead of
%blocking until an I/O operation completes, the web server could switch between
%ongoing connections maximizing this way the system's resource utilization.
%Designing the enclave to store SSL state specific values in a flat memory space
%would result in loosing the state of an ongoing SSL handshake when the web
%server switches to another connection. Our scheme uses a native implementation
%of a dynamic hash table that provides type checking and storing of arbitrary
%data structures. We used this data structure in order to map the state of
%ongoing SSL handshakes or established connections against an identifier and
%pay nearly constant time cost when an enclave tries to retrieve the state of
%an ongoing connection. Because the SSL session ID is considered established
%only when the handshake successfully completes, we assign an SGX specific
%identifier to an in-progress SSL handshake and switch the mapping key within
%the enclave to the SSL session ID when the handshake completes. Note that,
%this mechanism not only enables the enclave to deal with concurrent
%connections, but also lets us support SSL session resumption. In the interest
%of time, we left support of SessionTickets as future work.


\documentclass[../main.tex]{subfiles}

\begin{document}

In this section, we discuss the system components along with their
necessary modifications. We also emphasize on the challenges and the rationale
leading to a particular design approach that we have taken. We built a 
prototype of our design which consists of the following parts: NGINX, 
which is an event-driven web server achieving state-of-the-art performance,
LibreSSL as an implementation of the SSL/TLS protocol, OpenSGX as an emulation
environment of \Intel's SGX hardware and SGXBridge, a narrow interface that
utilizes UNIX named pipes to achieve IPC between the trusted and untrusted
components. Figure \ref{fig:implementation-overview} depicts an overview of our
prototype system.

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.25]{images/implementation.png}
  \caption{Secure Webserver block diagram }
  \label{fig:implementation-overview}
\end{figure}

\subsection{NGINX}

NGINX is an open source web server that uses an asynchronous event-driven
approach for handling requests from the clients. The rationale behind choosing
NGINX over Apache is the performance improvement it offers with the event
driven architecture. In NGINX, each worker process handles thousands of
connections simultaneously as opposed to Apache's thread per connection
approach. Furthermore, NGINX is lightweight, scalable and also gaining lot of
market share compared to Apache.

The NGINX server process can manage multiple clients simultaneously and the
request events are handled individually as they arrive. The server is capable
to offload the tasks to multiple worker processes in case of heavy incoming
traffic. This architecture introduced two implications in our design regarding
handling concurrent SSL handshakes and therefore concurrent connections.

First, OpenSGX comes without multi-threading support, fact that immediately
renders the enclave incapable of handling concurrent requests. We initially
considered an alternative design to provide multi-core support, in which an
enclave is launched for each worker and each enclave communicates with a shared
enclave to store/retrieve state specific to an active SSL handshake/session.
Though such a design would enable our system to support multiple NGINX workers,
it does not present a realistic approach for a production system with real SGX
hardware where multi-threading is natively supported. Thus we limit our current
model to a single core, and in the lack of possession of real SGX hardware we
leave multi-core support as future work.

Second, Nginx process will establish a unique SSL session ID for any 
connection only after the SSL handshake has successfully completed. It posed a 
challenge how to distinguish multiple concurrent connection data in the enclave,
prior to the TLS handshake completion.\footnote{In order to maximize
performance, a web server will try to switch between ongoing connections while
it waits for network I/O, which immediately poses the requirement for an
enclave to be aware of multiple SSL sessions. Regarding our design, not dealing
with concurrent connections, would mean that the enclave would only be able to
handle a single connection at a time which would have severe performance impact
to our design.}. To remedy this, we had to modify NGINX to generate an SGX specific ID, 
whenever a new connection request arrives. The enclave process uses this ID to distinguish
the data specific to a particular connection. Upon successful completion of the SSL handshake, the 
mapping key in the enclave will be switched to the appropriate session ID. We explain 
further in Section~\ref{subsec:opensgx} how this scheme enables our system to handle 
SSL session resumption.

\subsection{LibreSSL}
\label{subsec:libressl}
We used the LibreSSL library as an implementation of the SSL/TLS protocol for
our system. LibreSSL is a fork of OpenSSL aiming to provide a more secure
implementation and it has undergone major code pruning. The majority of the
changes compared to legacy OpenSSL are related to the security vulnerabilities
found in the latter. In our prototype system, both NGINX and SGX runtime are
linked to this library.

The LibreSSL variant attached to the NGINX process has been modified, such that
the implementation of all crypto operations are replaced with IPC
read()/write() stubs to SGXBridge (Section \ref{subsec:sgxbridge}). That is,
all the secure operations of an SSL handshake such as signing, verification,
key generation, encryption or decryption, will invoke an IPC request to the SGX
counterpart. We made careful cuts in LibreSSL's code in order to minimize the
code executed within the trusted component, thus effectively reducing the size
of the TCB. Most of the code executing within the enclave includes
cryptographic operations, except for a small volume of code responsible for
SSL state bookkeeping reasons\footnote{As mentioned in Section
\ref{sec:design}, upon exchange of the \texttt{ChangeCipherSpec} messages the
enclave prepares the environment for handling crypto operations specific to
the selected cipher.}. The rest of LibreSSL's code that handles tasks such as
connection establishment/termination and state manipulation, executes outside
of the enclave and is assumed to contain vulnerabilities and be potentially
compromised.

\subsection{OpenSGX}
\label{subsec:opensgx}
As described in Section \ref{sec:opensgx}, OpenSGX is an emulation
environment of \Intel~SGX. We used its runtime to build a prototype of
the designs description in Section~\ref{sec:design}. OpenSGX, however,
does not provide a complete implementation of SGX. Consequentially,
there were a few implementation decisions that were directly affected
by this limitation.

Specifically, OpenSGX does not support multiple threads within an
enclave. This means that, to support multiple server worker processes,
each worker would have to talk to a different enclave, otherwise, a
worker process would be blocked waiting for another worker's request
to complete (something that is not the case if a non-modified server
is in-use). We discuss this issue further in
Section~\ref{sec:futurework}.

Moreover, OpenSGX does not provide a way to programmatically invoke an
enclave from an untrusted component. To circumvent this limitation, we
implemented our design as two processes, one for the untrusted
component, and one for the \textit{enclave program}. The two processes
communicate using a named pipe. We used blocking
\texttt{read()}/\texttt{write()} operations to emulate the untrusted
component switching contexts to execute the \textit{enclave program}.

Finally, OpenSGX does not provide a way of accurately benchmarking
CPU cycle counts because it does not account for the number of cycles
each SGX instruction requires. This led to us estimating cycle counts
for an SGX instruction for the performance evaluation (see
Section~\ref{sec:perfeval}).


% TODO: Mention issues with the provisioning mechanishm TODO: Mention
% returning of IV/nonce to the untrusted part TODO: OpenSGX, anything
% interesting that not mentioned in the previous sections ???

% It is interesting to note that in the SGX part, we maintain a
% session cache based on a dynamic hash table ( SSL - LHASH routines )
% and this distinguishes multiple ongoing sessions with their
% corresponding session ids. This empowers us not only to handle
% concurrent SSL handshakes but also deal with the SSL session
% resumption within the enclave. (More details on cache
% implementation.. John? )

% During the first phase of development, we isolated all the private
% key related operations into the SGX component and returned only
% master key to the untrusted part of the server. To further enhance
% the security, we moved the symmetric session key generation as well
% to the SGX enclave. This brings all the cryptographic operations
% within the secure compartment. It’s interesting to note that, after
% the key block generation we had to return IV/nonce and key-block
% length back to the untrusted part of the server. These parameters
% are necessary for changing cipher states in the untrusted LibreSSL
% part. (more to expand by john ??)
%

\subsection{SGXBridge}
\label{subsec:sgxbridge}

SGXBridge is a Named Pipe IPC interface developed for exchanging data between
the trusted and untrusted process. It declares all the functions and data
structures required by the two components for data serialization. Each operation
that goes through SGXBridge requires two memcpy() and two I/O operations on the
named pipe\footnote{Note that, all I/O operations on a named pipe occur on
kernel buffers whose size may vary from 4K to 64K depending on the kernel
distribution and do not incur any actual disk I/O.}. It is worth mentioning
that in the current version of OpenSGX (v1.0), the interface will read/write
data to/from the stub (shared memory) in buffers of 512 bytes. This immediately
cancels a pipe buffer larger than this size, thus we designed SGXBridge to
follow this assumption. We mention though, this does not affect our performance
results, as our evaluation environment executes outside of OpenSGX's
runtime. For simplicity, we designed SGXBridge read()/write() operations to
follow a similar API to UNIX's I/O interface. For brevity reasons, we omit the
implementation details and we refer the reader to the documented code.

In real SGX hardware, the enclave will exist within a single process's virtual
memory and can be accessed directly without the requirement of an IPC
mechanism. We decided to use these interfaces for our project as it was an IPC
facility already available within the OpenSGX library.

\subsection{Implementation Phases and Tools used}
% \label{subsec:Implementation Phases and Tools used}
Our primary goal in implementation part was to understand the code flow in LibreSSL
engine and identify the specific functions and data structures that handles Server’s 
private key. We used a tool called Callgrind to discover the dynamic flow of execution 
(in NGINX and LibreSSL). Callgrind dynamically records, the sequence of function calls 
and provides a snapshot of the runtime behaviour of an application. We further used a
tool called KCachegrind, which graphically represent the large amount of data 
Callgrind produces and made it easy to navigate.
 
LibreSSL holds an SSL factory (SSL\_CTX) which can be used to create separate SSL objects
to identify each individual connection. SSL connection objects holds the entire 
data structures related to any particular connection and are used to do SSL handshakes
routines, reads, and writes. In the enclave we created a new SSL\_CTX factory and loaded
private key and certificate. Furthermore, we maintain a separate SSL connection object (SSL)
to isolate the data specific to a connection.   
 
Most of the abstract level functions pertaining to private/session key isolation were defined  
in following source files from Libressl library.
\begin{enumerate}
  \item S3\_srvr.c
  \item t1\_enc.c
\end{enumerate}
 
When NGINX receives a new HTTPS connection request after a classic \textit{accept()} function 
on the socket, it invokes the \textit{SSL\_Accept()} which causes the LibreSSL to perform the 
server side of SSL handshake. It is a blocking call until the entire handshake is complete. 
we had a comprehensive review of every switch-cases within this API and identified various 
internal functions (and associated data structures) invoked during the different steps 
involved in a handshake. At appropriate points within the sub functions we forwarded and read 
data to and from the enclave. For instance, during handshake after receiving a \textit{client\_hello}
message,LibreSSL loads the \textit{client-random} to SSL connection object and generates a \textit{server-random}. 
We have replaced this code such that \textit{client\_random} will be send to the enclave and read
the \textit{server\_random} generated within the enclave. Similarly, we identified specific snippets within
the code base, that require private key, then send the data to enclave to perform operations such as 
decrypting, signing, etc. 

In the later phase, we considered to further enhance the security by moving the decryption and encryption
to SGX enclave. To achieve this, we identified the routines that initialises a cipher context\footnote{A 
context structure that holds the algorithm information for a particular cipher which are a core part
of the SSL/TLS protocol.} (after negotiating with client) and the specific functions necessary
to perform encrypt/decrypt operation. In the enclave, we reproduced these functionalities and 
supported legacy RSA cipher AES256-SHA and ciphers with forward secrecy support such as 
CDHE-RSA-AES256-GCM-SHA384. We also support the AEAD (Authenticated Encryption with Associated Data)
mode of operation for encrypting/decrypting the application data. The AEAD operation is designed to 
provide authenticity, integrity and confidentiality in a single step. The underlying mode of operation
for the AEAD symmetric key crypto is GCM (Galois Counter Mode). GCM is highly efficient and yields 
state-of-the-art performance in commodity hardware by extensively utilising an instruction or 
hardware pipeline, in contrast to CBC mode which incurs significant pipeline stalls.

It’s interesting to note that at various points we used GDB debugger to break the execution and
step through the code flow. We developed and maintained a single bash script that automates the 
building and installation of all the software packages used within the system. For convenience, 
we add two compilation flags in LibreSSL: –enable-sgx and –enablesgx-keyblock. The former enables
the scenario where only the server’s private key is protected, while the latter enables the scenario
where both the server’s private key and the SSL session key-block are secured by the enclave.

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
