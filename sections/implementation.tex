% TODO: Add details about SSL session key management and book keeping in the
% enclave
%NGINX achieves state of the art performance in commodity hardware due to its
%event-driven design which renders the web server capable of scaling to
%hundends of thousands of concurrent connections. This architecture introduced
%an implication in our design regarding handling concurrent SSL handshakes.
%Although an implementation detail, we explain further a simple scheme we used
%for supporting NGINX's behaviour, as it was a crucial part of our final
%performance evaluation results\footnote{Not dealing with concurrent
%connections, would mean that the enclave would be only be able to handle a
%single connection at a time which would end up in severe performance penalties
%in our results.}. According to an event-driven architecture, instead of
%blocking until an I/O operation completes, the web server could switch between
%ongoing connections maximizing this way the system's resource utilization.
%Designing the enclave to store SSL state specific values in a flat memory space
%would result in loosing the state of an ongoing SSL handshake when the web
%server switches to another connection. Our scheme uses a native implementation
%of a dynamic hash table that provides type checking and storing of arbitrary
%data structures. We used this data structure in order to map the state of
%ongoing SSL handshakes or established connections against an identifier and
%pay nearly constant time cost when an enclave tries to retrieve the state of
%an ongoing connection. Because the SSL session ID is considered established
%only when the handshake successfully completes, we assign an SGX specific
%identifier to an in-progress SSL handshake and switch the mapping key within
%the enclave to the SSL session ID when the handshake completes. Note that,
%this mechanism not only enables the enclave to deal with concurrent
%connections, but also lets us support SSL session resumption. In the interest
%of time, we left support of SessionTickets as future work.


\documentclass[../main.tex]{subfiles}

\begin{document}

In this section, we highlight the system's components along with their
necessary modifications, the rationale and challenges behind them and discuss
the implementation considerations we made in realizing the final design. We
built a prototype of our design which consists of the following parts: NGINX
which is an event-driven web server achieving state-of-the-art performance,
LibreSSL as an implementation of the SSL/TLS protocol, OpenSGX as an emulation
environment of \Intel's SGX hardware and SGXBridge, a narrow interface that
utilizes UNIX named pipes to achieve IPC between the trusted and untrusted
components. Figure \ref{fig:implementation-overview} depicts an overview of our
prototype system.

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.25]{images/implementation.png}
  \caption{Secure Webserver block diagram }
  \label{fig:implementation-overview}
\end{figure}

\subsection{NGINX}

NGINX is an open source web server that uses an asynchronous event-driven
approach for handling requests from the clients. The rationale behind choosing
NGINX over Apache is the performance improvement it offers with the event
driven architecture. In NGINX, each worker process handles thousands of
connections simultaneously as opposed to Apache's thread per connection
approach. Furthermore NGINX is lightweight, scalable and also gaining lot of
market share compared to Apache.

The NGINX server process can manage multiple clients simultaneously and the
request events are handled individually as they arrive. The server is capable
to offload the tasks to multiple worker processes in case of heavy incoming
traffic. This architecture introduced two implications in our design regarding
handling concurrent SSL handshakes and therefore concurrent connections.

First, OpenSGX comes without multi-threading support, fact that immediately
renders the enclave incapable of handling concurrent requests. We initially
considered an alternative design to provide multi-core support, in which an
enclave is launched for each worker and each enclave communicates with a shared
enclave to store/retrieve state specific to an active SSL handshake/session.
Though such a design would enable our system to support multiple NGINX workers,
it does not present a realistic approach for a production system with real SGX
hardware where multi-threading is natively supported. Thus we limit our current
model to a single core, and in the lack of possesion of real SGX hardware we
leave multi-core support as future work.

Second, although not directly connected to NGINX's event-driven architecture
but an implementation detail we would have to deal with regardless of our
choice of web server, we discuss a simple scheme we used for enabling the
enclave to handle multiple connections at a time \footnote{In order to maximize
performance, a web server will try to switch between ongoing connections while
it waits for network I/O, which immediately poses the requirement for an
enclave to be aware of multiple SSL sessions. Regarding our design, not dealing
with concurrent connections, would mean that the enclave would only be able to
handle a single connection at a time which would have severe perfomance impact
to our design.}. Ultimately, the SSL session ID is used to map against a
session's state within the enclave, though this ID is only available when the
SSL handshake successfully completes. We modified NGINX to assign a randomly
generated SGX specific ID to a new incoming connection, which would be used by
the enclave until an SSL handshake completes and the mapping key changes to the
now established SSL session ID. We explain further in Section
\ref{subsec:opensgx} how this scheme enables our system to handle SSL session
resumption.

\subsection{LibreSSL}
\label{subsec:libressl}
We used the LibreSSL library as an implementation of the SSL/TLS protocol for
our system. LibreSSL is a fork of OpenSSL aiming to provide a more secure
implementation and it has undergone major code pruning. The majority of the
changes compared to legacy OpenSSL are related to the security vulnerabilities
found in the latter. In our prototype system, both NGINX and SGX runtime are
linked to this library.

The LibreSSL variant attached to the NGINX process has been modified, such that
 the implementation of all crypto operations are replaced with IPC
read()/write() stubs to SGXBridge (Section \ref{subsec:sgxbridge}). That is,
all the secure operations of an SSL handshake such as signing, verification,
key generation, encryption or decryption, will invoke an IPC request to the SGX
counterpart. We made careful cuts in LibreSSL's code in order to minimize the
code executed within the trusted component, thus effectively reducing the size
of the TCB. Most of the code executing within the enclave includes
cryptographic operations, except for a small volume of code responsible for
SSL state bookkeeping reasons\footnote{As mentioned in Section
\ref{sec:design}, upon exchange of the \texttt{ChangeCipherSpec} messages the
enclave prepares the environment for handling crypto operations specific to
the selected cipher.}. The rest of LibreSSL's code that handles tasks such as
connection establishment/termination and state manipulation, executes outside
of the enclave and is assumed to contain vulnerabilities and be potentially
owned.

Our system supports legacy RSA ciphers without forward secrecy support such as
AES256-SHA and ciphers with forward secrecy support such as
ECDHE-RSA-AES256-GCM-SHA384. We also support the AEAD (Authenticated Encryption
with Associated Data) mode of operation for encrypting/decrypting the
application data. The AEAD operation is designed to provide authenticity,
integrity and confidentiality in a single step. The underlying mode of
operation for the AEAD symmetric key crypto is GCM (Galois
Counter Mode). GCM is highly efficient and yields state-of-the-art performance
in commodity hardware by extensively utilizing an instruction or hardware
pipeline, in contrast to CBC mode which incurs significant pipeline stalls.

\subsection{OpenSGX}
\label{subsec:opensgx}
As described in Section \ref{sec:opensgx}, OpenSGX is an emulation
environment of \Intel~SGX. We used its runtime to build a prototype of
the designs description in Section~\ref{sec:design}. OpenSGX, however,
does not provide a complete implementation of SGX. Consequentially,
there were a few implementation decisions that were directly affected
by this limitation.

Specifically, OpenSGX does not support multiple threads within an
enclave. This means that, to support multiple server worker processes,
each worker would have to talk to a different enclave, otherwise, a
worker process would be blocked waiting for another worker's request
to complete (something that is not the case if a non-modified server
is in-use). We discuss this issue further in
Section~\ref{sec:futurework}.

Moreover, OpenSGX does not provide a way to programmatically invoke an
enclave from an untrusted component. To circumvent this limitation, we
implemented our design as two processes, one for the untrusted
component, and one for the \textit{enclave program}. The two processes
communicate using a named pipe. We used blocking
\texttt{read()}/\texttt{write()} operations to emulate the untrusted
component switching contexts to execute the \textit{enclave program}.

Finally, OpenSGX does not provide a way of accurately benchmarking
CPU cycle counts because it does not account for the number of cycles
each SGX instruction requires. This led to us estimating cycle counts
for an SGX instruction for the performance evaluation (see
Section~\ref{sec:perfeval}).


% TODO: Mention issues with the provisioning mechanishm TODO: Mention
% returning of IV/nonce to the untrusted part TODO: OpenSGX, anything
% interesting that not mentioned in the previous sections ???

% It is interesting to note that in the SGX part, we maintain a
% session cache based on a dynamic hash table ( SSL - LHASH routines )
% and this distinguishes multiple ongoing sessions with their
% corresponding session ids. This empowers us not only to handle
% concurrent SSL handshakes but also deal with the SSL session
% resumption within the enclave. (More details on cache
% implementation.. John? )

% During the first phase of development, we isolated all the private
% key related operations into the SGX component and returned only
% master key to the untrusted part of the server. To further enhance
% the security, we moved the symmetric session key generation as well
% to the SGX enclave. This brings all the cryptographic operations
% within the secure compartment. Itâ€™s interesting to note that, after
% the key block generation we had to return IV/nonce and key-block
% length back to the untrusted part of the server. These parameters
% are necessary for changing cipher states in the untrusted LibreSSL
% part. (more to expand by john ??)
%

\subsection{SGXBridge}
\label{subsec:sgxbridge}

SGXBridge is a Named Pipe IPC interface developed for exchanging data between
the trusted and untrusted process. It declares all the functions and data
structures required by the two components for data serialization. Each operation
that goes through SGXBridge requires two memcpy() and two I/O operations on the
named pipe\footnote{Note that, all I/O operations on a named pipe occur on
kernel buffers whose size may vary from 4K to 64K depending on the kernel
distribution and do not incur any actual disk I/O.}. It is worth mentioning
that in the current version of OpenSGX (v1.0), the interface will read/write
data to/from the stub (shared memory) in buffers of 512 bytes. This immediately
cancels a pipe buffer larger than this size, thus we designed SGXBridge to
follow this assumption. We mention though, this does not affect our performance
results, as our evaluation environment executes outside of OpenSGX's
runtime. For simplicity, we designed SGXBridge read()/write() operations to
follow a similar API to UNIX's I/O interface. For brevity reasons, we omit the
implementation details and we refer the reader to the documented code.

In real SGX hardware, the enclave will exist within a single process's virtual
memory and can be accessed directly without the requirement of an IPC
mechanism. We decided to use these interfaces for our project as it was an IPC
facility already available within the OpenSGX library.

\subsection{Compiler, Tools and Build system}
All the implementation parts were written in `C' programming language. At
various phases of the developments, we had to use tools such as Valgrind for
profiling, Callgrind for call stack analysis and GDB for debugging. We
developed and maintained a single bash script that automates the building and
installation of all the software packages used within the system.

For convenience, we add two compilation flags in LibreSSL: --enable-sgx and
--enable-sgx-keyblock. The former enables the scenario where only the server's
private key is protected, while the latter enables the scenario where both the
server's private key and the SSL session keyblock are secured by the enclave.

% TODO: Busy Wait, is it worth mentioning here or in test set up/perf eval ???

\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
